{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T03:29:41.625586Z",
     "start_time": "2025-03-21T03:29:36.762824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x106c713b0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Accuracy, ROC_AUC, Loss, Recall, Precision\n",
    "from torchinfo import summary\n",
    "from ignite.handlers import EarlyStopping\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "torch.use_deterministic_algorithms(True)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset From Disk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:21.309329Z",
     "start_time": "2025-03-21T01:50:20.635704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "design     10\n",
      "general     9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_file(data_filie, size):\n",
    "    df = pd.read_csv(data_filie)\n",
    "    if size > 0:\n",
    "        df = df[1: size]\n",
    "    raw_text = df['text'].tolist()\n",
    "    print(df['label'].value_counts())\n",
    "    raw_text_labels = [1 if sentiment == 'design' else 0 for sentiment in df['label'].tolist()]\n",
    "    return raw_text, raw_text_labels\n",
    "\n",
    "texts, labels = load_data_from_file('./combined_raw.csv', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:21.315611Z",
     "start_time": "2025-03-21T01:50:21.312623Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', \n",
    "                                  max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), \n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'label': torch.tensor(label)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bert_model_name = 'bert-base-uncased'\n",
    "num_classes = 2\n",
    "max_length = 128\n",
    "batch_size = 5\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer,  max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:21.541732Z",
     "start_time": "2025-03-21T01:50:21.316441Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construct the Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 1) # chose 1 since this is binary classification\n",
    "        \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:21.545280Z",
     "start_time": "2025-03-21T01:50:21.542532Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\") \n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:21.558657Z",
     "start_time": "2025-03-21T01:50:21.546001Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Training and Evaluation Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lithe/.conda/envs/conc_stab/lib/python3.10/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 2e-5\n",
    "\n",
    "\n",
    "model = BertClassifier(bert_model_name, num_classes).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:21.916599Z",
     "start_time": "2025-03-21T01:50:21.559634Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "=======================================================================================================================================\nLayer (type:depth-idx)                                       Input Shape               Output Shape              Param #\n=======================================================================================================================================\nBertClassifier                                               [5, 128]                  [5, 1]                    --\n├─BertModel: 1-1                                             --                        [5, 768]                  --\n│    └─BertEmbeddings: 2-1                                   --                        [5, 128, 768]             --\n│    │    └─Embedding: 3-1                                   [5, 128]                  [5, 128, 768]             23,440,896\n│    │    └─Embedding: 3-2                                   [5, 128]                  [5, 128, 768]             1,536\n│    │    └─Embedding: 3-3                                   [1, 128]                  [1, 128, 768]             393,216\n│    │    └─LayerNorm: 3-4                                   [5, 128, 768]             [5, 128, 768]             1,536\n│    │    └─Dropout: 3-5                                     [5, 128, 768]             [5, 128, 768]             --\n│    └─BertEncoder: 2-2                                      [5, 128, 768]             [5, 128, 768]             --\n│    │    └─ModuleList: 3-6                                  --                        --                        85,054,464\n│    └─BertPooler: 2-3                                       [5, 128, 768]             [5, 768]                  --\n│    │    └─Linear: 3-7                                      [5, 768]                  [5, 768]                  590,592\n│    │    └─Tanh: 3-8                                        [5, 768]                  [5, 768]                  --\n├─Dropout: 1-2                                               [5, 768]                  [5, 768]                  --\n├─Linear: 1-3                                                [5, 768]                  [5, 1]                    769\n=======================================================================================================================================\nTotal params: 109,483,009\nTrainable params: 109,483,009\nNon-trainable params: 0\nTotal mult-adds (M): 545.84\n=======================================================================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 531.66\nParams size (MB): 437.93\nEstimated Total Size (MB): 969.60\n======================================================================================================================================="
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model summary\n",
    "data_iter = iter(train_dataloader)\n",
    "sample_batch = next(data_iter)  # Get first batch of data\n",
    "\n",
    "if isinstance(sample_batch, dict):\n",
    "    input_ids = sample_batch['input_ids']\n",
    "    attention_mask = sample_batch['attention_mask']\n",
    "elif isinstance(sample_batch, (list, tuple)):  \n",
    "    input_ids, attention_mask, _ = sample_batch \n",
    "else:\n",
    "    raise TypeError(\"Unexpected data format from DataLoader\")\n",
    "\n",
    "summary(model, input_data=(input_ids, attention_mask), \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"], device=device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:22.481640Z",
     "start_time": "2025-03-21T01:50:21.917495Z"
    }
   },
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_step(engine, batch):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    \n",
    "    labels = batch['label'].to(device, dtype=torch.float32)\n",
    "    \n",
    "    labels = labels.unsqueeze(1)\n",
    "  \n",
    "    \n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    loss = nn.BCEWithLogitsLoss()(outputs, labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def evaluation_step(engine, batch):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            prediction_probability = torch.sigmoid(logits)\n",
    "            predictions = (prediction_probability >= 0.5).float()\n",
    "            \n",
    "            actual_labels = labels\n",
    "        \n",
    "    return logits, prediction_probability, predictions,  actual_labels\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "trainer = Engine(train_step)\n",
    "evaluator  = Engine(evaluation_step)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=1))\n",
    "def run_validation():\n",
    "    evaluator.run(val_dataloader)\n",
    "    \n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=1))\n",
    "def log_validation():\n",
    "    metrics = evaluator.state.metrics\n",
    "    \n",
    "    auc_scores.append(metrics['roc_auc'])\n",
    "    precision.append(metrics['precision'])\n",
    "    recall.append(metrics['recall'])\n",
    "    accuracy_scores.append(metrics['accuracy'])\n",
    "    bce_losses.append(metrics['bce_loss'])\n",
    "    f1_score.append(metrics['f1_score'])\n",
    "    \n",
    "    \n",
    "    epochs.append(trainer.state.epoch)\n",
    "    \n",
    "    \n",
    "    results = {\n",
    "        'epoch': epochs,\n",
    "        'auc_score': auc_scores,\n",
    "        'accuracy_score': accuracy_scores,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "    }\n",
    "    \n",
    "    results_df = pd.DataFrame(data=results)\n",
    "    results_df.to_csv(f\"./results/saved_metrics/{bert_model_name}.csv\", index=False)\n",
    "    \n",
    "    print(f\"Epoch: {trainer.state.epoch}, Accuracy: {metrics['accuracy']},  ROC_AUC: {metrics['roc_auc']} BCE_LOSS: {metrics['bce_loss']}\")\n",
    "\n",
    "\n",
    "Accuracy(output_transform= lambda x: (x[2], x[3])).attach(evaluator, \"accuracy\")\n",
    "ROC_AUC(output_transform=lambda x: (x[1], x[3])).attach(evaluator, \"roc_auc\")\n",
    "\n",
    "recall = Recall(output_transform=lambda x: (x[2], x[3]), average=False)\n",
    "recall.attach(evaluator, 'recall')\n",
    "\n",
    "precision = Precision(output_transform=lambda x: (x[2], x[3]), average=False)\n",
    "precision.attach(evaluator, \"precision\")\n",
    "\n",
    "f1_score = (precision * recall * 2 / (precision + recall))\n",
    "f1_score.attach(evaluator, 'f1_score')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:22.491856Z",
     "start_time": "2025-03-21T01:50:22.484204Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Early Stopping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<ignite.engine.events.RemovableEventHandle at 0x17e6889a0>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_criterion  = torch.nn.BCEWithLogitsLoss()\n",
    "loss_metric = Loss(loss_criterion, output_transform=lambda x: (x[0],x[2]))\n",
    "\n",
    "loss_metric.attach(evaluator, 'bce_loss')\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['bce_loss']\n",
    "    return -val_loss\n",
    "    \n",
    "early_stopping_handler = EarlyStopping(patience=3, score_function=score_function, trainer=trainer)\n",
    "evaluator.add_event_handler(Events.COMPLETED, early_stopping_handler)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:50:22.496995Z",
     "start_time": "2025-03-21T01:50:22.492857Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Accuracy: 0.5,  ROC_AUC: 1.0 BCE_LOSS: 0.5492638349533081\n",
      "Epoch: 2, Accuracy: 1.0,  ROC_AUC: 1.0 BCE_LOSS: 0.6243481636047363\n",
      "Epoch: 3, Accuracy: 0.5,  ROC_AUC: 1.0 BCE_LOSS: 0.5698870420455933\n",
      "Epoch: 4, Accuracy: 0.5,  ROC_AUC: 1.0 BCE_LOSS: 0.44497644901275635\n",
      "Epoch: 5, Accuracy: 0.5,  ROC_AUC: 1.0 BCE_LOSS: 0.4266374707221985\n",
      "Epoch: 6, Accuracy: 0.75,  ROC_AUC: 1.0 BCE_LOSS: 0.39084553718566895\n",
      "Epoch: 7, Accuracy: 0.75,  ROC_AUC: 1.0 BCE_LOSS: 0.3880262076854706\n",
      "Epoch: 8, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.2792815864086151\n",
      "Epoch: 9, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.22532238066196442\n",
      "Epoch: 10, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.20606346428394318\n",
      "Epoch: 11, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.2116970419883728\n",
      "Epoch: 12, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.22975772619247437\n",
      "Epoch: 13, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.20265600085258484\n",
      "Epoch: 14, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.15795055031776428\n",
      "Epoch: 15, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.12163817137479782\n",
      "Epoch: 16, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.10032903403043747\n",
      "Epoch: 17, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.08934848010540009\n",
      "Epoch: 18, Accuracy: 0.5,  ROC_AUC: 0.3333333333333333 BCE_LOSS: 0.07997310161590576\n",
      "Epoch: 19, Accuracy: 0.5,  ROC_AUC: 0.3333333333333333 BCE_LOSS: 0.07076512277126312\n",
      "Epoch: 20, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.06230296939611435\n",
      "Epoch: 21, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.05661251023411751\n",
      "Epoch: 22, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.052778732031583786\n",
      "Epoch: 23, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.04978969320654869\n",
      "Epoch: 24, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.04689536616206169\n",
      "Epoch: 25, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.044114939868450165\n",
      "Epoch: 26, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.04157882183790207\n",
      "Epoch: 27, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.03989341855049133\n",
      "Epoch: 28, Accuracy: 0.5,  ROC_AUC: 0.6666666666666666 BCE_LOSS: 0.03858121111989021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m recall \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      7\u001B[0m f1_score \u001B[38;5;241m=\u001B[39m[]\n\u001B[0;32m----> 9\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/ignite/engine/engine.py:889\u001B[0m, in \u001B[0;36mEngine.run\u001B[0;34m(self, data, max_epochs, epoch_length)\u001B[0m\n\u001B[1;32m    886\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mdataloader \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    888\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minterrupt_resume_enabled:\n\u001B[0;32m--> 889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    891\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_legacy()\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/ignite/engine/engine.py:932\u001B[0m, in \u001B[0;36mEngine._internal_run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_generator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_as_gen()\n\u001B[1;32m    931\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 932\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_internal_run_generator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m out:\n\u001B[1;32m    934\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_run_generator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/ignite/engine/engine.py:990\u001B[0m, in \u001B[0;36mEngine._internal_run_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    988\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    989\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine run is terminating due to exception: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 990\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    992\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    993\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/ignite/engine/engine.py:644\u001B[0m, in \u001B[0;36mEngine._handle_exception\u001B[0;34m(self, e)\u001B[0m\n\u001B[1;32m    642\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mEXCEPTION_RAISED, e)\n\u001B[1;32m    643\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 644\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/ignite/engine/engine.py:956\u001B[0m, in \u001B[0;36mEngine._internal_run_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    953\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataloader_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    954\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_engine()\n\u001B[0;32m--> 956\u001B[0m epoch_time_taken \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_once_on_dataset_as_gen()\n\u001B[1;32m    958\u001B[0m \u001B[38;5;66;03m# time is available for handlers but must be updated after fire\u001B[39;00m\n\u001B[1;32m    959\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mtimes[Events\u001B[38;5;241m.\u001B[39mEPOCH_COMPLETED\u001B[38;5;241m.\u001B[39mname] \u001B[38;5;241m=\u001B[39m epoch_time_taken\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/ignite/engine/engine.py:1077\u001B[0m, in \u001B[0;36mEngine._run_once_on_dataset_as_gen\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1074\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mITERATION_STARTED)\n\u001B[1;32m   1075\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_terminate_or_interrupt()\n\u001B[0;32m-> 1077\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39moutput \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_event(Events\u001B[38;5;241m.\u001B[39mITERATION_COMPLETED)\n\u001B[1;32m   1079\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_terminate_or_interrupt()\n",
      "Cell \u001B[0;32mIn[9], line 17\u001B[0m, in \u001B[0;36mtrain_step\u001B[0;34m(engine, batch)\u001B[0m\n\u001B[1;32m     14\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(input_ids\u001B[38;5;241m=\u001B[39minput_ids, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask)\n\u001B[1;32m     16\u001B[0m loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss()(outputs, labels)\n\u001B[0;32m---> 17\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/torch/_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    625\u001B[0m     )\n\u001B[0;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/conc_stab/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "bce_losses = [] \n",
    "precision = []\n",
    "recall = []\n",
    "f1_score =[]\n",
    "\n",
    "trainer.run(train_dataloader, 100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:51:59.836388Z",
     "start_time": "2025-03-21T01:50:22.498168Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./results/saved_models/{bert_model_name}.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-21T01:51:59.837332Z",
     "start_time": "2025-03-21T01:51:59.837273Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results Plotting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.plot(epochs, auc_scores, 'r--', epochs, accuracy_scores, 'b--')\n",
    "plt.legend(['AUC Score', 'Validation Accuracy',])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
